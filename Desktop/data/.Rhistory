getwd()
setwd(/Users/harsimran_ranu03/Desktop/datasciencecoursera)
setwd(Users/harsimran_ranu03/Desktop/datasciencecoursera)
add2 <- funtion(x,y){x+y}
add2 <- function(x,y){x+y}
add2(4,9)
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
pollutantmean <- function(directory, pollutant = "sulfate", id = 1:332) {
if(grep("specdata", directory) == 1) {
directory <- ("./specdata/")
mean_vector <- c()
all_files <- as.character( list.files(directory) )
file_paths <- paste(directory, all_files, sep="")
for(i in id) {
current_file <- read.csv(file_paths[i], header=T, sep=",")
head(current_file)
pollutant
na_removed <- current_file[!is.na(current_file[, pollutant]), pollutant]
mean_vector <- c(mean_vector, na_removed)
}
result <- mean(mean_vector)
return(round(result, 3))
}
pollutantmean <- function(directory, pollutant, id = 1:332) {
setwd(file.path(getwd(), directory)) ## setting the directory
total = 0                            ## the sum of all observed values of pollutant (either sulfate or nitrate)
observations = 0                     ## the total number of observed values of pollutant (either sulfate or nitrate)
#Looping thru the directory's files specified in the 'id' argument
for (i in id)
{
## Due to the format of the filename, i.e 001, 010  instead of 1, 10. I became aware that the following method works but not efficient,
## but at the time of the completion of this assignment, it was the only way I knew how to do it.
if (i <10) {
data <- read.csv(paste("0","0", as.character(i), ".csv", sep=""),  ## for example, if 'id' =7, we get 007.csv
header = T,
na.strings=c("NA","NaN", " "))
}
else if (i>=10 & i<100) {
data <- read.csv(paste("0", as.character(i), ".csv", sep=""),  ## for example, if 'id' = 17, we get 017.csv
header = T,
na.strings=c("NA","NaN", " ")
)
}
else       {
data <- read.csv(paste(as.character(i), ".csv", sep=""),     ## Normal
header = T,
na.strings=c("NA","NaN", " ")
)
}
## getting rid of all the "NA" values and, consequently, all the non-complete ovservations (the ones with at least one NA in row)
data = na.omit(data)
##  cumulative addition of the complete observations
observations = observations + nrow(data)
## depending the poluttant ( sulfate or nitrate), we aggregate the observed values
if (pollutant == "sulfate") {total = total + sum(data$sulfate)}
else {total = total + sum(data$nitrate)}
}
## reset directory path
setwd("..")
## returning the mean of the pollutant values
return (total/observations)
}
pollutantmean("specdata", "sulfate", 1:8)
pollutantmean <- function(directory, pollutant, id = 1:332) {
setwd(file.path(getwd(), directory)) ## setting the directory
total = 0                            ## the sum of all observed values of pollutant (either sulfate or nitrate)
observations = 0                     ## the total number of observed values of pollutant (either sulfate or nitrate)
#Looping thru the directory's files specified in the 'id' argument
for (i in id)
{
## Due to the format of the filename, i.e 001, 010  instead of 1, 10. I became aware that the following method works but not efficient,
## but at the time of the completion of this assignment, it was the only way I knew how to do it.
if (i <10) {
data <- read.csv(paste("0","0", as.character(i), ".csv", sep=""),  ## for example, if 'id' =7, we get 007.csv
header = T,
na.strings=c("NA","NaN", " "))
}
else if (i>=10 & i<100) {
data <- read.csv(paste("0", as.character(i), ".csv", sep=""),  ## for example, if 'id' = 17, we get 017.csv
header = T,
na.strings=c("NA","NaN", " ")
)
}
else       {
data <- read.csv(paste(as.character(i), ".csv", sep=""),     ## Normal
header = T,
na.strings=c("NA","NaN", " ")
)
}
## getting rid of all the "NA" values and, consequently, all the non-complete ovservations (the ones with at least one NA in row)
data = na.omit(data)
##  cumulative addition of the complete observations
observations = observations + nrow(data)
## depending the poluttant ( sulfate or nitrate), we aggregate the observed values
if (pollutant == "sulfate") {total = total + sum(data$sulfate)}
else {total = total + sum(data$nitrate)}
}
## reset directory path
setwd("..")
## returning the mean of the pollutant values
return (total/observations)
}
pollutantmean("specdata", "sulfate", 1:10)
library(httr)
direccion <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
archivo <- "ss06hid.csv"
download.file(direccion, archivo, method="curl")
data <- read.csv("ss06hid.csv")
logicalvector <- data$ACR==3 & data$AGS==6
first3 <- which(logicalvector)[1:3] # which() treats NAs as FALSE
first3
direccion2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
archivo2 <- "jeff.jpg"
download.file(direccion2, archivo2, method="curl")
foto <- readJPEG("jeff.jpg", native = TRUE)
quantile(foto)
library(jpeg)
direccion2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
archivo2 <- "jeff.jpg"
download.file(direccion2, archivo2, method="curl")
foto <- readJPEG("jeff.jpg", native = TRUE)
quantile(foto)
install.packages("jpeg")
library(jpeg)
direccion2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
archivo2 <- "jeff.jpg"
download.file(direccion2, archivo2, method="curl")
foto <- readJPEG("jeff.jpg", native = TRUE)
quantile(foto)
library(data.table)
direccion3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
archivo3 <- "GDP.csv"
download.file(direccion3, archivo3, method="curl")
GDP <- data.table(read.csv("GDP.csv", skip = 4, nrows = 191))
GDP <- GDP[X != ""]
GDP <- GDP[, list(X, X.1, X.3, X.4)]
setnames(GDP, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP", "Long.Name", "GDP"))
direccion4 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
archivo4 <- "EDSTATS_Country.csv"
download.file(direccion4, archivo4, method="curl")
EDSTATS <- data.table(read.csv("EDSTATS_Country.csv"))
data2 <- merge(GDP, EDSTATS, all = TRUE, by = c("CountryCode"))
sum(!is.na(unique(data2$rankingGDP)))
data2[order(rankingGDP, decreasing = TRUE), list(CountryCode, Long.Name.x, Long.Name.y, rankingGDP, GDP)][13]
data2[, mean(rankingGDP, na.rm = TRUE), by = Income.Group]
breaks <- quantile(data2$rankingGDP, probs = seq(0, 1, 0.2), na.rm = TRUE)
data2$quantileGDP <- cut(data2$rankingGDP, breaks = breaks)
data2[Income.Group == "Lower middle income", .N, by = c("Income.Group", "quantileGDP")]
setwd("~/Desktop/UCI HAR Dataset")
library(plyr)
# Step 1
# Merge the training and test sets to create one data set
###############################################################################
x_train <- read.table("train/X_train.txt")
y_train <- read.table("train/y_train.txt")
subject_train <- read.table("train/subject_train.txt")
x_test <- read.table("test/X_test.txt")
y_test <- read.table("test/y_test.txt")
subject_test <- read.table("test/subject_test.txt")
# create 'x' data set
x_data <- rbind(x_train, x_test)
# create 'y' data set
y_data <- rbind(y_train, y_test)
# create 'subject' data set
subject_data <- rbind(subject_train, subject_test)
# Step 2
# Extract only the measurements on the mean and standard deviation for each measurement
###############################################################################
features <- read.table("features.txt")
# get only columns with mean() or std() in their names
mean_and_std_features <- grep("-(mean|std)\\(\\)", features[, 2])
# subset the desired columns
x_data <- x_data[, mean_and_std_features]
# correct the column names
names(x_data) <- features[mean_and_std_features, 2]
# Step 3
# Use descriptive activity names to name the activities in the data set
###############################################################################
activities <- read.table("activity_labels.txt")
# update values with correct activity names
y_data[, 1] <- activities[y_data[, 1], 2]
# correct column name
names(y_data) <- "activity"
# Step 4
# Appropriately label the data set with descriptive variable names
###############################################################################
# correct column name
names(subject_data) <- "subject"
# bind all the data in a single data set
all_data <- cbind(x_data, y_data, subject_data)
# Step 5
# Create a second, independent tidy data set with the average of each variable
# for each activity and each subject
###############################################################################
# 66 <- 68 columns but last two (activity & subject)
averages_data <- ddply(all_data, .(subject, activity), function(x) colMeans(x[, 1:66]))
write.table(averages_data, "averages_data.txt", row.name=FALSE)
library(knitr)
knit2html("codebook.Rmd");
library(knitr)
knit2html("codebook.Rmd");
library(knitr)
knit2html("codebook.Rmd");
library(knitr)
knit2html("codebook.Rmd");
library(knitr)
knit2html("codebook.Rmd");
library(knitr)
knit2html("codebook.Rmd");
library(plyr)
# Step 1
# Merge the training and test sets to create one data set
###############################################################################
x_train <- read.table("train/X_train.txt")
y_train <- read.table("train/y_train.txt")
subject_train <- read.table("train/subject_train.txt")
x_test <- read.table("test/X_test.txt")
y_test <- read.table("test/y_test.txt")
subject_test <- read.table("test/subject_test.txt")
# create 'x' data set
x_data <- rbind(x_train, x_test)
# create 'y' data set
y_data <- rbind(y_train, y_test)
# create 'subject' data set
subject_data <- rbind(subject_train, subject_test)
# Step 2
# Extract only the measurements on the mean and standard deviation for each measurement
###############################################################################
features <- read.table("features.txt")
# get only columns with mean() or std() in their names
mean_and_std_features <- grep("-(mean|std)\\(\\)", features[, 2])
# subset the desired columns
x_data <- x_data[, mean_and_std_features]
# correct the column names
names(x_data) <- features[mean_and_std_features, 2]
# Step 3
# Use descriptive activity names to name the activities in the data set
###############################################################################
activities <- read.table("activity_labels.txt")
# update values with correct activity names
y_data[, 1] <- activities[y_data[, 1], 2]
# correct column name
names(y_data) <- "activity"
# Step 4
# Appropriately label the data set with descriptive variable names
###############################################################################
# correct column name
names(subject_data) <- "subject"
# bind all the data in a single data set
all_data <- cbind(x_data, y_data, subject_data)
# Step 5
# Create a second, independent tidy data set with the average of each variable
# for each activity and each subject
###############################################################################
# 66 <- 68 columns but last two (activity & subject)
averages_data <- ddply(all_data, .(subject, activity), function(x) colMeans(x[, 1:66]))
write.table(averages_data, "averages_data.txt", row.name=FALSE)
library(knitr)
knit2html("codebook.Rmd");
library(knitr)
knit2html("codebook.Rmd");
library(knitr)
knit2html("codebook.Rmd");
library(plyr)
# Step 1
# Merge the training and test sets to create one data set
###############################################################################
x_train <- read.table("train/X_train.txt")
y_train <- read.table("train/y_train.txt")
subject_train <- read.table("train/subject_train.txt")
x_test <- read.table("test/X_test.txt")
y_test <- read.table("test/y_test.txt")
subject_test <- read.table("test/subject_test.txt")
# create 'x' data set
x_data <- rbind(x_train, x_test)
# create 'y' data set
y_data <- rbind(y_train, y_test)
# create 'subject' data set
subject_data <- rbind(subject_train, subject_test)
# Step 2
# Extract only the measurements on the mean and standard deviation for each measurement
###############################################################################
features <- read.table("features.txt")
# get only columns with mean() or std() in their names
mean_and_std_features <- grep("-(mean|std)\\(\\)", features[, 2])
# subset the desired columns
x_data <- x_data[, mean_and_std_features]
# correct the column names
names(x_data) <- features[mean_and_std_features, 2]
# Step 3
# Use descriptive activity names to name the activities in the data set
###############################################################################
activities <- read.table("activity_labels.txt")
# update values with correct activity names
y_data[, 1] <- activities[y_data[, 1], 2]
# correct column name
names(y_data) <- "activity"
# Step 4
# Appropriately label the data set with descriptive variable names
###############################################################################
# correct column name
names(subject_data) <- "subject"
# bind all the data in a single data set
all_data <- cbind(x_data, y_data, subject_data)
# Step 5
# Create a second, independent tidy data set with the average of each variable
# for each activity and each subject
###############################################################################
# 66 <- 68 columns but last two (activity & subject)
averages_data <- ddply(all_data, .(subject, activity), function(x) colMeans(x[, 1:66]))
write.table(averages_data, "averages_data.txt", row.name=FALSE)
library(knitr)
knit2html("codebook.Rmd");
library(knitr)
knit2html("codebook.Rmd");
setwd("~/Desktop/data")
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl,destfile="./data/Dataset.zip",method="curl")
unzip(zipfile="./data/Dataset.zip",exdir="./data")
path_rf <- file.path("./data" , "UCI HAR Dataset")
files<-list.files(path_rf, recursive=TRUE)
files
dataActivityTest  <- read.table(file.path(path_rf, "test" , "Y_test.txt" ),header = FALSE)
dataActivityTrain <- read.table(file.path(path_rf, "train", "Y_train.txt"),header = FALSE)
dataSubjectTrain <- read.table(file.path(path_rf, "train", "subject_train.txt"),header = FALSE)
dataSubjectTest  <- read.table(file.path(path_rf, "test" , "subject_test.txt"),header = FALSE)
dataFeaturesTest  <- read.table(file.path(path_rf, "test" , "X_test.txt" ),header = FALSE)
dataFeaturesTrain <- read.table(file.path(path_rf, "train", "X_train.txt"),header = FALSE)
str(dataActivityTest)
str(dataActivityTrain)
str(dataSubjectTrain)
str(dataSubjectTest)
str(dataFeaturesTest)
str(dataFeaturesTrain)
dataSubject <- rbind(dataSubjectTrain, dataSubjectTest)
dataActivity<- rbind(dataActivityTrain, dataActivityTest)
dataFeatures<- rbind(dataFeaturesTrain, dataFeaturesTest)
names(dataSubject)<-c("subject")
names(dataActivity)<- c("activity")
dataFeaturesNames <- read.table(file.path(path_rf, "features.txt"),head=FALSE)
names(dataFeatures)<- dataFeaturesNames$V2
dataCombine <- cbind(dataSubject, dataActivity)
Data <- cbind(dataFeatures, dataCombine)
subdataFeaturesNames<-dataFeaturesNames$V2[grep("mean\\(\\)|std\\(\\)", dataFeaturesNames$V2)]
selectedNames<-c(as.character(subdataFeaturesNames), "subject", "activity" )
Data<-subset(Data,select=selectedNames)
str(Data)
activityLabels <- read.table(file.path(path_rf, "activity_labels.txt"),header = FALSE)
head(Data$activity,30)
names(Data)<-gsub("^t", "time", names(Data))
names(Data)<-gsub("^f", "frequency", names(Data))
names(Data)<-gsub("Acc", "Accelerometer", names(Data))
names(Data)<-gsub("Gyro", "Gyroscope", names(Data))
names(Data)<-gsub("Mag", "Magnitude", names(Data))
names(Data)<-gsub("BodyBody", "Body", names(Data))
names(Data)
library(plyr);
Data2<-aggregate(. ~subject + activity, Data, mean)
Data2<-Data2[order(Data2$subject,Data2$activity),]
write.table(Data2, file = "tidydata.txt",row.name=FALSE)
library(knitr)
knit2html("codebook.Rmd");
library(knitr)
knit2html("codebook.Rmd");
library(knitr)
knit2html("codebook.Rmd");
